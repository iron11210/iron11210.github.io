<!-- build time:Wed Dec 17 2025 12:57:55 GMT+0800 (中国标准时间) --><!DOCTYPE html><script async src="https://www.googletagmanager.com/gtag/js?id=G-DPVE7Y0QX9"></script><script>function gtag(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-DPVE7Y0QX9")</script><html lang="zh-CN"><head><meta charset="UTF-8"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=2"><meta name="theme-color" content="#FFF"><link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon.png"><link rel="icon" type="image/ico" sizes="32x32" href="/images/favicon.ico"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><link rel="alternate" type="application/rss+xml" title="杂项笔记" href="http://example.com/rss.xml"><link rel="alternate" type="application/atom+xml" title="杂项笔记" href="http://example.com/atom.xml"><link rel="alternate" type="application/json" title="杂项笔记" href="http://example.com/feed.json"><link rel="stylesheet" href="//fonts.googleapis.com/css?family=Mulish:300,300italic,400,400italic,700,700italic%7CFredericka%20the%20Great:300,300italic,400,400italic,700,700italic%7CNoto%20Serif%20JP:300,300italic,400,400italic,700,700italic%7CNoto%20Serif%20SC:300,300italic,400,400italic,700,700italic%7CInconsolata:300,300italic,400,400italic,700,700italic&display=swap&subset=latin,latin-ext"><link rel="stylesheet" href="/css/app.css?v=0.2.5"><link rel="canonical" href="http://example.com/2025/06/02/computer/DataAnalyze/lec8%20Principles%20ofData%20Science%20-%20%E5%89%AF%E6%9C%AC%20(3)/"><title>lec7 Principles ofData Science - 数据分析 - 计算机科学 | IRON = 杂项笔记</title><meta name="generator" content="Hexo 7.3.0"></head><body itemscope itemtype="http://schema.org/WebPage"><div id="loading"><div class="cat"><div class="body"></div><div class="head"><div class="face"></div></div><div class="foot"><div class="tummy-end"></div><div class="bottom"></div><div class="legs left"></div><div class="legs right"></div></div><div class="paw"><div class="hands left"></div><div class="hands right"></div></div></div></div><div id="container"><header id="header" itemscope itemtype="http://schema.org/WPHeader"><div class="inner"><div id="brand"><div class="pjax"><h1 itemprop="name headline">lec7 Principles ofData Science</h1><div class="meta"><span class="item" title="创建时间：2025-06-02 10:59:31"><span class="icon"><i class="ic i-calendar"></i> </span><span class="text">发表于</span> <time itemprop="dateCreated datePublished" datetime="2025-06-02T10:59:31+08:00">2025-06-02</time></span></div></div></div><nav id="nav"><div class="inner"><div class="toggle"><div class="lines" aria-label="切换导航栏"><span class="line"></span> <span class="line"></span> <span class="line"></span></div></div><ul class="menu"><li class="item title"><a href="/" rel="start">IRON</a></li></ul><ul class="right"><li class="item theme"><i class="ic i-sun"></i></li><li class="item search"><i class="ic i-search"></i></li></ul></div></nav></div><div id="imgs" class="pjax"><ul><li class="item" data-background-image="https://dlink.host/wx4.sinaimg.cn/large/006Tzddnly8htqg1pgsrij30sg0sgtdo.jpg"></li><li class="item" data-background-image="https://dlink.host/wx2.sinaimg.cn/large/006Tzddnly8htqg0x2lhcg3074074e7q.gif"></li><li class="item" data-background-image="https://dlink.host/wx4.sinaimg.cn/large/006Tzddnly8htpyghxhuvg30b40b41jo.gif"></li><li class="item" data-background-image="https://dlink.host/wx2.sinaimg.cn/large/006Tzddnly8htqg1keshmj30sg0sgjvu.jpg"></li><li class="item" data-background-image="https://dlink.host/wx1.sinaimg.cn/large/006Tzddnly8htqg0l4jv0j30sg0sgjuv.jpg"></li><li class="item" data-background-image="https://dlink.host/wx4.sinaimg.cn/large/006Tzddnly8htqg1pgsrij30sg0sgtdo.jpg"></li></ul></div><div id="waves"><svg class="waves" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 24 150 28" preserveAspectRatio="none" shape-rendering="auto"><defs><path id="gentle-wave" d="M-160 44c30 0 58-18 88-18s 58 18 88 18 58-18 88-18 58 18 88 18 v44h-352z"/></defs><g class="parallax"><use xlink:href="#gentle-wave" x="48" y="0"/><use xlink:href="#gentle-wave" x="48" y="3"/><use xlink:href="#gentle-wave" x="48" y="5"/><use xlink:href="#gentle-wave" x="48" y="7"/></g></svg></div></header><main><div class="inner"><div id="main" class="pjax"><div class="article wrap"><div class="breadcrumb" itemscope itemtype="https://schema.org/BreadcrumbList"><i class="ic i-home"></i> <span><a href="/">首页</a></span><i class="ic i-angle-right"></i> <span itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem"><a href="/categories/computer/" itemprop="item" rel="index" title="分类于 计算机科学"><span itemprop="name">计算机科学</span></a><meta itemprop="position" content="1"></span><i class="ic i-angle-right"></i> <span class="current" itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem"><a href="/categories/computer/DataAnalyze/" itemprop="item" rel="index" title="分类于 数据分析"><span itemprop="name">数据分析</span></a><meta itemprop="position" content="2"></span></div><article itemscope itemtype="http://schema.org/Article" class="post block" lang="zh-CN"><link itemprop="mainEntityOfPage" href="http://example.com/2025/06/02/computer/DataAnalyze/lec8%20Principles%20ofData%20Science%20-%20%E5%89%AF%E6%9C%AC%20(3)/"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="image" content="/images/avatar.jpg"><meta itemprop="name" content="IRON"><meta itemprop="description" content=", "></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="杂项笔记"></span><div class="body md" itemprop="articleBody"><h1 id="聚类clustering"><a class="anchor" href="#聚类clustering">#</a> 聚类（Clustering)</h1><h2 id="一-聚类的概念"><a class="anchor" href="#一-聚类的概念">#</a> 一、聚类的概念</h2><ul><li>聚类是一种 <strong>无监督学习方法</strong></li><li>目标是：将相似的数据点分在同一个 “簇”（cluster）中</li><li>没有预先的标签，完全基于数据之间的 “相似性” 划分</li></ul><hr><h2 id="二-聚类的用途"><a class="anchor" href="#二-聚类的用途">#</a> 二、聚类的用途</h2><ul><li>文档分组、客户画像、基因数据分析、股票走势分群等</li><li>聚类可以帮助我们发现数据中的 “自然结构”</li></ul><hr><h2 id="三-相似性度量方法"><a class="anchor" href="#三-相似性度量方法">#</a> 三、相似性度量方法</h2><p>用于计算两个数据点之间的 “相似程度”（或 “距离”）：</p><table><thead><tr><th>距离类型</th><th>定义</th><th>说明</th><th></th><th></th></tr></thead><tbody><tr><td>曼哈顿距离（L1）</td><td>( d(i,j) = <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>∑</mo></mrow><annotation encoding="application/x-tex">\sum</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.00001em;vertical-align:-.25001em"></span><span class="mop op-symbol small-op" style="position:relative;top:-.0000050000000000050004em">∑</span></span></span></span></td><td>x_i - x_j</td><td>)</td><td>抗异常值</td></tr><tr><td>欧几里得距离（L2）</td><td>( d(i,j) =<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msqrt><mrow><mo>∑</mo><mo stretchy="false">(</mo><msub><mi>x</mi><mi>i</mi></msub><mo>−</mo><msub><mi>x</mi><mi>j</mi></msub><msup><mo stretchy="false">)</mo><mn>2</mn></msup></mrow></msqrt></mrow><annotation encoding="application/x-tex">\sqrt{\sum (x_i - x_j)^2}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.24em;vertical-align:-.32305399999999995em"></span><span class="mord sqrt"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.916946em"><span class="svg-align" style="top:-3.2em"><span class="pstrut" style="height:3.2em"></span><span class="mord" style="padding-left:1em"><span class="mop op-symbol small-op" style="position:relative;top:-.0000050000000000050004em">∑</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.31166399999999994em"><span style="top:-2.5500000000000003em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.311664em"><span style="top:-2.5500000000000003em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:.05724em">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.286108em"><span></span></span></span></span></span></span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.740108em"><span style="top:-2.9890000000000003em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span><span style="top:-2.8769460000000002em"><span class="pstrut" style="height:3.2em"></span><span class="hide-tail" style="min-width:1.02em;height:1.28em"><svg width="400em" height="1.28em" viewbox="0 0 400000 1296" preserveaspectratio="xMinYMin slice"><path d="M263,681c0.7,0,18,39.7,52,119
c34,79.3,68.167,158.7,102.5,238c34.3,79.3,51.8,119.3,52.5,120
c340,-704.7,510.7,-1060.3,512,-1067
l0 -0
c4.7,-7.3,11,-11,19,-11
H40000v40H1012.3
s-271.3,567,-271.3,567c-38.7,80.7,-84,175,-136,283c-52,108,-89.167,185.3,-111.5,232
c-22.3,46.7,-33.8,70.3,-34.5,71c-4.7,4.7,-12.3,7,-23,7s-12,-1,-12,-1
s-109,-253,-109,-253c-72.7,-168,-109.3,-252,-110,-252c-10.7,8,-22,16.7,-34,26
c-22,17.3,-33.3,26,-34,26s-26,-26,-26,-26s76,-59,76,-59s76,-60,76,-60z
M1001 80h400000v40h-400000z"/></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.32305399999999995em"><span></span></span></span></span></span></span></span></span> )</td><td>几何直观</td><td></td><td></td></tr><tr><td>闵可夫斯基距离（Lq）</td><td>广义形式，q 可调节</td><td>L1 和 L2 的推广</td><td></td><td></td></tr></tbody></table><hr><h2 id="四-聚类的主要类型"><a class="anchor" href="#四-聚类的主要类型">#</a> 四、聚类的主要类型</h2><h3 id="1️⃣-划分式聚类partitional-clustering"><a class="anchor" href="#1️⃣-划分式聚类partitional-clustering">#</a> 1️⃣ 划分式聚类（Partitional Clustering）</h3><p>直接将数据<strong>一次性划分为 k 个簇</strong>，每个点只能属于一个簇。</p><h4 id="核心逻辑"><a class="anchor" href="#核心逻辑">#</a> 🔑 核心逻辑：</h4><blockquote><p>假设我们知道有 k 个簇，目标是让簇内相似度最大，簇间相似度最小。</p></blockquote><h4 id="关键点"><a class="anchor" href="#关键点">#</a> 🛠 关键点：</h4><ol><li><p><strong>从整体出发</strong>：不看谁和谁特别像，而是一次性给所有点 “分组”</p></li><li><p><strong>设定目标函数</strong>（如 K-Means 中最小化 SSE）</p></li><li><p><strong>迭代优化</strong>：不断调整划分，使目标函数越来越好</p></li></ol><h4 id="类比理解"><a class="anchor" href="#类比理解">#</a> 🌀 类比理解：</h4><blockquote><p>把一堆人平均分成 k 个房间，通过不断调换位置来让 “同一房间的人兴趣最相似”</p></blockquote><ul><li>每个点只属于一个簇</li><li>代表方法：<strong>K-Means</strong></li></ul><h3 id="2️⃣-层次聚类hierarchical-clustering"><a class="anchor" href="#2️⃣-层次聚类hierarchical-clustering">#</a> 2️⃣ 层次聚类（Hierarchical Clustering）</h3><p>构建一个<strong>嵌套的簇结构</strong>，形成 “树状图（dendrogram）”，你可以在任何层级切断这棵树来得到你想要的簇数。</p><h4 id="核心逻辑-2"><a class="anchor" href="#核心逻辑-2">#</a> 🔑 核心逻辑：</h4><blockquote><p>从最小单位（每个点）出发，<strong>优先合并 / 分裂最近的样本</strong>，逐步构造出整棵 “聚类树”。</p></blockquote><h4 id="关键点-2"><a class="anchor" href="#关键点-2">#</a> 🛠 关键点：</h4><ol><li><p><strong>从局部关系开始</strong>：谁最像就先合并谁</p></li><li><p>不设定簇数，而是构建一棵层次结构（树）</p></li><li><p><strong>可以从任意层切断</strong>来选择你要的簇数（后验决定）</p></li></ol><h4 id="类比理解-2"><a class="anchor" href="#类比理解-2">#</a> 🌀 类比理解：</h4><blockquote><p>把每个人看作一个独立社交圈，然后让 “最熟的人” 先组合，逐步扩展到大家都成一个大圈</p></blockquote><ul><li>生成树状结构（dendrogram）</li><li>方法：<ul><li>凝聚式（Agglomerative，自底向上）</li><li>分裂式（Divisive，自顶向下）</li></ul></li></ul><hr><h2 id="五-k-means-聚类算法详解"><a class="anchor" href="#五-k-means-聚类算法详解">#</a> 五、K-Means 聚类算法详解</h2><h3 id="基本流程"><a class="anchor" href="#基本流程">#</a> 基本流程：</h3><ol><li>设定簇数 (k)，随机初始化中心点</li><li>将每个点分配给最近的中心（按距离）</li><li>重新计算每个簇的中心（所有点均值）</li><li>重复步骤 2-3，直到收敛</li></ol><h3 id="算法特点"><a class="anchor" href="#算法特点">#</a> 算法特点：</h3><ul><li>简单、易于实现</li><li>对初始中心敏感</li><li>时间复杂度：<strong>O(n × k × i × d)</strong></li></ul><hr><h2 id="六-层次聚类详解agglomerative"><a class="anchor" href="#六-层次聚类详解agglomerative">#</a> 六、层次聚类详解（Agglomerative）</h2><h3 id="步骤"><a class="anchor" href="#步骤">#</a> 步骤：</h3><ol><li>每个点单独作为一簇</li><li>计算所有簇之间的距离</li><li>合并距离最近的两个簇</li><li>重新计算新簇与其他簇之间的距离</li><li>重复，直到只剩一个簇或达到期望数量</li></ol><h3 id="距离更新策略"><a class="anchor" href="#距离更新策略">#</a> 距离更新策略：</h3><ul><li><strong>Single Linkage</strong>：最短点对距离</li><li><strong>Complete Linkage</strong>：最长点对距离</li><li><strong>Average Linkage</strong>：平均点对距离</li></ul><hr><h2 id="七-聚类结果评估预告"><a class="anchor" href="#七-聚类结果评估预告">#</a> 七、聚类结果评估（预告）</h2><p>聚类没有标签，但仍可评估效果：</p><ul><li>外部指标：Homogeneity、Completeness、V-measure（需要真实标签）</li><li>内部指标：SSE、Silhouette Coefficient（不依赖标签）</li><li>相对指标：比较多个聚类结果</li></ul><hr><h2 id="总结"><a class="anchor" href="#总结">#</a> ✅ 总结</h2><blockquote><p>聚类就是通过 “距离函数” 判断数据点间的相似性，再将相似的点归为一组。常用算法包括 K-Means 和层次聚类，评估方法依赖具体任务与数据特性。</p></blockquote><h1 id="二-聚类评估与簇数选择"><a class="anchor" href="#二-聚类评估与簇数选择">#</a> 📌 二、聚类评估与簇数选择</h1><hr><h3 id="1-评估指标如何判断聚类效果好不好"><a class="anchor" href="#1-评估指标如何判断聚类效果好不好">#</a> ✅ 1. 评估指标（如何判断聚类效果好不好）</h3><h4 id="外部指标需要真实标签"><a class="anchor" href="#外部指标需要真实标签">#</a> 🔹 外部指标（需要真实标签）：</h4><p>用于比较聚类结果与真实分类标签的一致性：</p><ul><li><strong>Homogeneity（同质性）</strong>：每个簇是否只包含一个真实类</li><li><strong>Completeness（完整性）</strong>：每个类是否被完整地分在一个簇中</li><li><strong>V-measure</strong>：Homogeneity 与 Completeness 的调和平均（类似 F1 分数）</li></ul><h4 id="内部指标无需标签"><a class="anchor" href="#内部指标无需标签">#</a> 🔹 内部指标（无需标签）：</h4><p>用于衡量聚类结构本身的紧凑性与分离性：</p><ul><li><strong>SSE（Sum of Squared Errors）平方误差和</strong>：<ul><li>衡量簇内点到簇中心的距离平方之和</li><li>越小表示簇越紧凑</li></ul></li><li><strong>Silhouette 系数（轮廓系数）</strong>：<ul><li>衡量点在 “本簇中的紧密程度” 和 “与最近其他簇的区分度”</li></ul></li></ul><h4 id="相对指标"><a class="anchor" href="#相对指标">#</a> 🔹 相对指标：</h4><ul><li>用于比较两个聚类结构哪一个更优（可以带标签，也可以不带）</li></ul><hr><h3 id="2-silhouette-系数轮廓系数"><a class="anchor" href="#2-silhouette-系数轮廓系数">#</a> ✅ 2. Silhouette 系数（轮廓系数）</h3><h4 id="定义"><a class="anchor" href="#定义">#</a> 📖 定义：</h4><ul><li>衡量每个点在本簇内的 “紧密度” 和与其他簇的 “分离度”</li><li>Silhouette 值 (s) 计算方式如下：</li></ul><p \max(a, b)>s = \frac{b - a}</p><p>其中：</p><ul><li>(a)：该点与同簇中其他点的平均距离</li><li>(b)：该点与最近邻簇中所有点的平均距离</li></ul><h4 id="取值范围与解释"><a class="anchor" href="#取值范围与解释">#</a> ✅ 取值范围与解释：</h4><ul><li>( s <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>∈</mo></mrow><annotation encoding="application/x-tex">\in</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.5782em;vertical-align:-.0391em"></span><span class="mrel">∈</span></span></span></span> [-1, 1] )</li><li>( s <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>→</mo></mrow><annotation encoding="application/x-tex">\to</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.36687em;vertical-align:0"></span><span class="mrel">→</span></span></span></span> 1 )：聚类良好（点靠近本簇中心，远离其他簇）</li><li>( s <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>≈</mo></mrow><annotation encoding="application/x-tex">\approx</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.48312em;vertical-align:0"></span><span class="mrel">≈</span></span></span></span> 0 )：点位于边界</li><li>(s &lt; 0)：聚类可能错误（点离本簇更远）</li></ul><h4 id="作用"><a class="anchor" href="#作用">#</a> 🛠 作用：</h4><ul><li>用于评估聚类质量</li><li>可帮助选择合适的簇数 (k)：平均 Silhouette 值最大的 ( k ) 更合适</li></ul><hr><h1 id="降维部分总结主成分分析pca"><a class="anchor" href="#降维部分总结主成分分析pca">#</a> 📉 降维部分总结：主成分分析（PCA）</h1><hr><h3 id="一-为什么要降维"><a class="anchor" href="#一-为什么要降维">#</a> ✅ 一、为什么要降维？</h3><ul><li>高维数据存在冗余、噪声、计算量大等问题</li><li>降维目标：<ul><li>降低维度，提高效率</li><li>便于数据可视化</li><li>保留尽可能多的 “有用信息”</li><li>消除变量间的冗余（相关性）</li></ul></li></ul><hr><h3 id="二-主成分分析pca的核心思想"><a class="anchor" href="#二-主成分分析pca的核心思想">#</a> ✅ 二、主成分分析（PCA）的核心思想</h3><ul><li>将原始高维数据转换为一组 <strong>新的正交主成分</strong></li><li>每个主成分都是原始特征的 <strong>线性组合</strong></li><li>主成分按解释的 “数据方差” 大小排序</li><li>只保留前几个主成分就能近似还原原数据</li></ul><hr><h3 id="三-pca-步骤流程"><a class="anchor" href="#三-pca-步骤流程">#</a> ✅ 三、PCA 步骤流程</h3><ol><li><strong>数据标准化</strong>（中心化）</li><li><strong>构建协方差矩阵</strong></li><li><strong>计算特征值和特征向量</strong><ul><li>特征向量：主成分方向</li><li>特征值：对应方向上解释的方差</li></ul></li><li><strong>选择前 (k) 个主成分</strong></li><li><strong>将原始数据投影到主成分空间中</strong></li></ol><hr><h3 id="四-协方差矩阵-covx"><a class="anchor" href="#四-协方差矩阵-covx">#</a> ✅ 四、协方差矩阵 Cov (X)</h3><ul><li>协方差衡量两个变量是否具有线性相关性</li><li>矩阵结构如下（以 x, y, z 为例）：</li></ul><p></p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">       | Var(x)   Cov(x,y)  Cov(x,z) |</span><br><span class="line">Cov(X) =| Cov(y,x) Var(y)   Cov(y,z) |</span><br><span class="line">       | Cov(z,x) Cov(z,y)  Var(z)   |</span><br></pre></td></tr></table></figure><p></p><ul><li>协方差大表示变量冗余；PCA 就是<strong>找出能解释最多变异性的新轴</strong></li></ul><hr><h3 id="五-pca-应用iris-数据集示例"><a class="anchor" href="#五-pca-应用iris-数据集示例">#</a> ✅ 五、PCA 应用：Iris 数据集示例</h3><ul><li>原始数据：4 个变量（萼片长宽、花瓣长宽）</li><li>经过 PCA 后：<ul><li>前两个主成分可解释 <strong>95.8%</strong> 的数据方差</li><li>可将 4 维数据映射到 2 维空间，方便可视化和聚类</li></ul></li></ul><hr><h3 id="六-pca-的优势与局限"><a class="anchor" href="#六-pca-的优势与局限">#</a> ✅ 六、PCA 的优势与局限</h3><h4 id="优势"><a class="anchor" href="#优势">#</a> ✅ 优势：</h4><ul><li>不依赖标签，适用于无监督任务</li><li>提升算法效率</li><li>有效缓解 “维度灾难”</li><li>可用于可视化与预处理</li></ul><h4 id="局限"><a class="anchor" href="#局限">#</a> ❌ 局限：</h4><ul><li>只能捕捉<strong>线性关系</strong></li><li>不适用于类别型变量</li><li>主成分不具备原始特征的语义解释性</li></ul><hr><h3 id="总结一句话"><a class="anchor" href="#总结一句话">#</a> 📌 总结一句话：</h3><blockquote><p><strong>PCA 是将高维空间的相关变量转换为低维空间中无关主成分，最大限度保留数据信息的降维技术。</strong></p></blockquote></div><footer><div class="meta"><span class="item"><span class="icon"><i class="ic i-calendar-check"></i> </span><span class="text">更新于</span> <time title="修改时间：2025-05-10 17:23:22" itemprop="dateModified" datetime="2025-05-10T17:23:22+08:00">2025-05-10</time> </span><span id="2025/06/02/computer/DataAnalyze/lec8 Principles ofData Science - 副本 (3)/" class="item leancloud_visitors" data-flag-title="lec7 Principles ofData Science" title="阅读次数"><span class="icon"><i class="ic i-eye"></i> </span><span class="text">阅读次数</span> <span class="leancloud-visitors-count"></span> <span class="text">次</span></span></div><div class="reward"><button><i class="ic i-heartbeat"></i> 赞赏</button><p>请我喝[茶]~(￣▽￣)~*</p><div id="qr"><div><img data-src="/images/wechatpay.png" alt="IRON 微信支付"><p>微信支付</p></div><div><img data-src="/images/alipay.png" alt="IRON 支付宝"><p>支付宝</p></div><div><img data-src="/images/paypal.png" alt="IRON 贝宝"><p>贝宝</p></div></div></div><div id="copyright"><ul><li class="author"><strong>本文作者： </strong>IRON <i class="ic i-at"><em>@</em></i>杂项笔记</li><li class="link"><strong>本文链接：</strong> <a href="http://example.com/2025/06/02/computer/DataAnalyze/lec8%20Principles%20ofData%20Science%20-%20%E5%89%AF%E6%9C%AC%20(3)/" title="lec7 Principles ofData Science">http://example.com/2025/06/02/computer/DataAnalyze/lec8 Principles ofData Science - 副本 (3)/</a></li><li class="license"><strong>版权声明： </strong>本站所有文章除特别声明外，均采用 <span class="exturl" data-url="aHR0cHM6Ly9jcmVhdGl2ZWNvbW1vbnMub3JnL2xpY2Vuc2VzL2J5LW5jLXNhLzQuMC9kZWVkLnpo"><i class="ic i-creative-commons"><em>(CC)</em></i>BY-NC-SA</span> 许可协议。转载请注明出处！</li></ul></div></footer></article></div><div class="post-nav"><div class="item left"><a href="/2025/06/02/computer/DataAnalyze/lec8%20Principles%20ofData%20Science%20-%20%E5%89%AF%E6%9C%AC%20(2)/" itemprop="url" rel="prev" data-background-image="https:&#x2F;&#x2F;dlink.host&#x2F;wx2.sinaimg.cn&#x2F;large&#x2F;006Tzddnly8htqg1keshmj30sg0sgjvu.jpg" title="lec7 Principles ofData Science"><span class="type">上一篇</span> <span class="category"><i class="ic i-flag"></i> 数据分析</span><h3>lec7 Principles ofData Science</h3></a></div><div class="item right"><a href="/2025/06/02/computer/DataAnalyze/lec8%20Principles%20ofData%20Science%20-%20%E5%89%AF%E6%9C%AC%20(4)/" itemprop="url" rel="next" data-background-image="https:&#x2F;&#x2F;dlink.host&#x2F;wx1.sinaimg.cn&#x2F;large&#x2F;006Tzddnly8htqg0l4jv0j30sg0sgjuv.jpg" title="lec7 Principles ofData Science"><span class="type">下一篇</span> <span class="category"><i class="ic i-flag"></i> 数据分析</span><h3>lec7 Principles ofData Science</h3></a></div></div><div class="wrap" id="comments"></div></div><div id="sidebar"><div class="inner"><div class="panels"><div class="inner"><div class="contents panel pjax" data-title="文章目录"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E8%81%9A%E7%B1%BBclustering"><span class="toc-number">1.</span> <span class="toc-text">聚类（Clustering)</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%80-%E8%81%9A%E7%B1%BB%E7%9A%84%E6%A6%82%E5%BF%B5"><span class="toc-number">1.1.</span> <span class="toc-text">一、聚类的概念</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BA%8C-%E8%81%9A%E7%B1%BB%E7%9A%84%E7%94%A8%E9%80%94"><span class="toc-number">1.2.</span> <span class="toc-text">二、聚类的用途</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%89-%E7%9B%B8%E4%BC%BC%E6%80%A7%E5%BA%A6%E9%87%8F%E6%96%B9%E6%B3%95"><span class="toc-number">1.3.</span> <span class="toc-text">三、相似性度量方法</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%9B%9B-%E8%81%9A%E7%B1%BB%E7%9A%84%E4%B8%BB%E8%A6%81%E7%B1%BB%E5%9E%8B"><span class="toc-number">1.4.</span> <span class="toc-text">四、聚类的主要类型</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1%EF%B8%8F%E2%83%A3-%E5%88%92%E5%88%86%E5%BC%8F%E8%81%9A%E7%B1%BBpartitional-clustering"><span class="toc-number">1.4.1.</span> <span class="toc-text">1️⃣ 划分式聚类（Partitional Clustering）</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%A0%B8%E5%BF%83%E9%80%BB%E8%BE%91"><span class="toc-number">1.4.1.1.</span> <span class="toc-text">🔑 核心逻辑：</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%85%B3%E9%94%AE%E7%82%B9"><span class="toc-number">1.4.1.2.</span> <span class="toc-text">🛠 关键点：</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%B1%BB%E6%AF%94%E7%90%86%E8%A7%A3"><span class="toc-number">1.4.1.3.</span> <span class="toc-text">🌀 类比理解：</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2%EF%B8%8F%E2%83%A3-%E5%B1%82%E6%AC%A1%E8%81%9A%E7%B1%BBhierarchical-clustering"><span class="toc-number">1.4.2.</span> <span class="toc-text">2️⃣ 层次聚类（Hierarchical Clustering）</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%A0%B8%E5%BF%83%E9%80%BB%E8%BE%91-2"><span class="toc-number">1.4.2.1.</span> <span class="toc-text">🔑 核心逻辑：</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%85%B3%E9%94%AE%E7%82%B9-2"><span class="toc-number">1.4.2.2.</span> <span class="toc-text">🛠 关键点：</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%B1%BB%E6%AF%94%E7%90%86%E8%A7%A3-2"><span class="toc-number">1.4.2.3.</span> <span class="toc-text">🌀 类比理解：</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BA%94-k-means-%E8%81%9A%E7%B1%BB%E7%AE%97%E6%B3%95%E8%AF%A6%E8%A7%A3"><span class="toc-number">1.5.</span> <span class="toc-text">五、K-Means 聚类算法详解</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%9F%BA%E6%9C%AC%E6%B5%81%E7%A8%8B"><span class="toc-number">1.5.1.</span> <span class="toc-text">基本流程：</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%AE%97%E6%B3%95%E7%89%B9%E7%82%B9"><span class="toc-number">1.5.2.</span> <span class="toc-text">算法特点：</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%85%AD-%E5%B1%82%E6%AC%A1%E8%81%9A%E7%B1%BB%E8%AF%A6%E8%A7%A3agglomerative"><span class="toc-number">1.6.</span> <span class="toc-text">六、层次聚类详解（Agglomerative）</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%AD%A5%E9%AA%A4"><span class="toc-number">1.6.1.</span> <span class="toc-text">步骤：</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%B7%9D%E7%A6%BB%E6%9B%B4%E6%96%B0%E7%AD%96%E7%95%A5"><span class="toc-number">1.6.2.</span> <span class="toc-text">距离更新策略：</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%83-%E8%81%9A%E7%B1%BB%E7%BB%93%E6%9E%9C%E8%AF%84%E4%BC%B0%E9%A2%84%E5%91%8A"><span class="toc-number">1.7.</span> <span class="toc-text">七、聚类结果评估（预告）</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%80%BB%E7%BB%93"><span class="toc-number">1.8.</span> <span class="toc-text">✅ 总结</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E4%BA%8C-%E8%81%9A%E7%B1%BB%E8%AF%84%E4%BC%B0%E4%B8%8E%E7%B0%87%E6%95%B0%E9%80%89%E6%8B%A9"><span class="toc-number">2.</span> <span class="toc-text">📌 二、聚类评估与簇数选择</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-%E8%AF%84%E4%BC%B0%E6%8C%87%E6%A0%87%E5%A6%82%E4%BD%95%E5%88%A4%E6%96%AD%E8%81%9A%E7%B1%BB%E6%95%88%E6%9E%9C%E5%A5%BD%E4%B8%8D%E5%A5%BD"><span class="toc-number">2.0.1.</span> <span class="toc-text">✅ 1. 评估指标（如何判断聚类效果好不好）</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%A4%96%E9%83%A8%E6%8C%87%E6%A0%87%E9%9C%80%E8%A6%81%E7%9C%9F%E5%AE%9E%E6%A0%87%E7%AD%BE"><span class="toc-number">2.0.1.1.</span> <span class="toc-text">🔹 外部指标（需要真实标签）：</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%86%85%E9%83%A8%E6%8C%87%E6%A0%87%E6%97%A0%E9%9C%80%E6%A0%87%E7%AD%BE"><span class="toc-number">2.0.1.2.</span> <span class="toc-text">🔹 内部指标（无需标签）：</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%9B%B8%E5%AF%B9%E6%8C%87%E6%A0%87"><span class="toc-number">2.0.1.3.</span> <span class="toc-text">🔹 相对指标：</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-silhouette-%E7%B3%BB%E6%95%B0%E8%BD%AE%E5%BB%93%E7%B3%BB%E6%95%B0"><span class="toc-number">2.0.2.</span> <span class="toc-text">✅ 2. Silhouette 系数（轮廓系数）</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%AE%9A%E4%B9%89"><span class="toc-number">2.0.2.1.</span> <span class="toc-text">📖 定义：</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%8F%96%E5%80%BC%E8%8C%83%E5%9B%B4%E4%B8%8E%E8%A7%A3%E9%87%8A"><span class="toc-number">2.0.2.2.</span> <span class="toc-text">✅ 取值范围与解释：</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BD%9C%E7%94%A8"><span class="toc-number">2.0.2.3.</span> <span class="toc-text">🛠 作用：</span></a></li></ol></li></ol></li></ol><li class="toc-item toc-level-1"><a class="toc-link" href="#%E9%99%8D%E7%BB%B4%E9%83%A8%E5%88%86%E6%80%BB%E7%BB%93%E4%B8%BB%E6%88%90%E5%88%86%E5%88%86%E6%9E%90pca"><span class="toc-number">3.</span> <span class="toc-text">📉 降维部分总结：主成分分析（PCA）</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%80-%E4%B8%BA%E4%BB%80%E4%B9%88%E8%A6%81%E9%99%8D%E7%BB%B4"><span class="toc-number">3.0.1.</span> <span class="toc-text">✅ 一、为什么要降维？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BA%8C-%E4%B8%BB%E6%88%90%E5%88%86%E5%88%86%E6%9E%90pca%E7%9A%84%E6%A0%B8%E5%BF%83%E6%80%9D%E6%83%B3"><span class="toc-number">3.0.2.</span> <span class="toc-text">✅ 二、主成分分析（PCA）的核心思想</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%89-pca-%E6%AD%A5%E9%AA%A4%E6%B5%81%E7%A8%8B"><span class="toc-number">3.0.3.</span> <span class="toc-text">✅ 三、PCA 步骤流程</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%9B%9B-%E5%8D%8F%E6%96%B9%E5%B7%AE%E7%9F%A9%E9%98%B5-covx"><span class="toc-number">3.0.4.</span> <span class="toc-text">✅ 四、协方差矩阵 Cov (X)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BA%94-pca-%E5%BA%94%E7%94%A8iris-%E6%95%B0%E6%8D%AE%E9%9B%86%E7%A4%BA%E4%BE%8B"><span class="toc-number">3.0.5.</span> <span class="toc-text">✅ 五、PCA 应用：Iris 数据集示例</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%85%AD-pca-%E7%9A%84%E4%BC%98%E5%8A%BF%E4%B8%8E%E5%B1%80%E9%99%90"><span class="toc-number">3.0.6.</span> <span class="toc-text">✅ 六、PCA 的优势与局限</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BC%98%E5%8A%BF"><span class="toc-number">3.0.6.1.</span> <span class="toc-text">✅ 优势：</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%B1%80%E9%99%90"><span class="toc-number">3.0.6.2.</span> <span class="toc-text">❌ 局限：</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%80%BB%E7%BB%93%E4%B8%80%E5%8F%A5%E8%AF%9D"><span class="toc-number">3.0.7.</span> <span class="toc-text">📌 总结一句话：</span></a></li></ol></li></div><div class="related panel pjax" data-title="系列文章"><ul><li><a href="/2025/03/28/computer/DataAnalyze/lec6%20Hypothesis%20Testingand%20Evaluation/" rel="bookmark" title="lec6 Hypothesis Testingand Evaluation">lec6 Hypothesis Testingand Evaluation</a></li><li><a href="/2025/04/24/computer/DataAnalyze/lec7%20Association%20RuleMining/" rel="bookmark" title="lec7 Association RuleMining">lec7 Association RuleMining</a></li><li><a href="/2025/05/10/computer/DataAnalyze/%E6%9C%9F%E6%9C%AB%E5%A4%8D%E4%B9%A05/" rel="bookmark" title="期末复习5">期末复习5</a></li><li><a href="/2025/06/02/computer/DataAnalyze/%E6%9C%9F%E6%9C%AB%E5%A4%8D%E4%B9%A01/" rel="bookmark" title="期末复习1">期末复习1</a></li><li><a href="/2025/06/02/computer/DataAnalyze/lec8%20Principles%20ofData%20Science%20-%20%E5%89%AF%E6%9C%AC%20(2)/" rel="bookmark" title="lec7 Principles ofData Science">lec7 Principles ofData Science</a></li><li class="active"><a href="/2025/06/02/computer/DataAnalyze/lec8%20Principles%20ofData%20Science%20-%20%E5%89%AF%E6%9C%AC%20(3)/" rel="bookmark" title="lec7 Principles ofData Science">lec7 Principles ofData Science</a></li><li><a href="/2025/06/02/computer/DataAnalyze/lec8%20Principles%20ofData%20Science%20-%20%E5%89%AF%E6%9C%AC%20(4)/" rel="bookmark" title="lec7 Principles ofData Science">lec7 Principles ofData Science</a></li><li><a href="/2025/06/06/computer/DataAnalyze/%E6%9C%9F%E6%9C%AB%E5%A4%8D%E4%B9%A02/" rel="bookmark" title="期末复习2">期末复习2</a></li></ul></div><div class="overview panel" data-title="站点概览"><div class="author" itemprop="author" itemscope itemtype="http://schema.org/Person"><img class="image" itemprop="image" alt="IRON" data-src="/images/avatar.jpg"><p class="name" itemprop="name">IRON</p><div class="description" itemprop="description"></div></div><nav class="state"><div class="item posts"><a href="/archives/"><span class="count">141</span> <span class="name">文章</span></a></div><div class="item categories"><a href="/categories/"><span class="count">20</span> <span class="name">分类</span></a></div></nav><div class="social"><span class="exturl item music" data-url="aHR0cHM6Ly9tdXNpYy4xNjMuY29tLyMvdXNlci9ob21lP2lkPTU1MDgyNDI1Nw==" title="https:&#x2F;&#x2F;music.163.com&#x2F;#&#x2F;user&#x2F;home?id&#x3D;550824257"><i class="ic i-cloud-music"></i></span> <a href="/zhouy6577@gmail.com" title="zhouy6577@gmail.com" class="item email"><i class="ic i-envelope"></i></a></div><ul class="menu"><li class="item"><a href="/" rel="section"><i class="ic i-home"></i>主页</a></li><li class="item"><a href="/about/" rel="section"><i class="ic i-user"></i>关于</a></li><li class="item dropdown"><a href="javascript:void(0);"><i class="ic i-feather"></i>文章</a><ul class="submenu"><li class="item"><a href="/archives/" rel="section"><i class="ic i-list-alt"></i>归档</a></li><li class="item"><a href="/categories/" rel="section"><i class="ic i-th"></i>分类</a></li><li class="item"><a href="/tags/" rel="section"><i class="ic i-tags"></i>标签</a></li></ul></li><li class="item"><a href="/links/" rel="section"><i class="ic i-magic"></i>links</a></li></ul></div></div></div><ul id="quick"><li class="prev pjax"><a href="/2025/06/02/computer/DataAnalyze/lec8%20Principles%20ofData%20Science%20-%20%E5%89%AF%E6%9C%AC%20(2)/" rel="prev" title="上一篇"><i class="ic i-chevron-left"></i></a></li><li class="up"><i class="ic i-arrow-up"></i></li><li class="down"><i class="ic i-arrow-down"></i></li><li class="next pjax"><a href="/2025/06/02/computer/DataAnalyze/lec8%20Principles%20ofData%20Science%20-%20%E5%89%AF%E6%9C%AC%20(4)/" rel="next" title="下一篇"><i class="ic i-chevron-right"></i></a></li><li class="percent"></li></ul></div></div><div class="dimmer"></div></div></main><footer id="footer"><div class="inner"><div class="widgets"><div class="rpost pjax"><h2>随机文章</h2><ul><li class="item"><div class="breadcrumb"><a href="/categories/computer/" title="分类于 计算机科学">计算机科学</a> <i class="ic i-angle-right"></i> <a href="/categories/computer/front/" title="分类于 前端">前端</a> <i class="ic i-angle-right"></i> <a href="/categories/computer/front/prattle/" title="分类于 杂谈">杂谈</a></div><span><a href="/2024/03/01/computer/front/prattle/Vuex%E7%9A%84%E5%AD%A6%E4%B9%A0%E5%BF%83%E5%BE%97/" title="Vue学习心得">Vue学习心得</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/game-engine/" title="分类于 游戏引擎">游戏引擎</a> <i class="ic i-angle-right"></i> <a href="/categories/game-engine/unity/" title="分类于 unity">unity</a> <i class="ic i-angle-right"></i> <a href="/categories/game-engine/unity/unityBasics/" title="分类于 unity基础">unity基础</a></div><span><a href="/2024/08/03/game-engine/unity/unityBasics/unity%E4%B8%AD%E5%9F%BA%E6%9C%AC%E7%B1%BB%E7%9A%84%E4%BD%BF%E7%94%A8-2/" title="unity中基本类的使用-2">unity中基本类的使用-2</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/game-engine/" title="分类于 游戏引擎">游戏引擎</a> <i class="ic i-angle-right"></i> <a href="/categories/game-engine/unity/" title="分类于 unity">unity</a> <i class="ic i-angle-right"></i> <a href="/categories/game-engine/unity/unityBasics/" title="分类于 unity基础">unity基础</a></div><span><a href="/2024/09/04/game-engine/unity/unityBasics/%E4%B8%80%E4%BA%9B%E5%8A%9F%E8%83%BD%E5%92%8C%E4%B8%8D%E6%87%82%E7%9A%84%E7%82%B9%E7%9A%84%E8%AE%B0%E5%BD%95/" title="一些功能和不懂的点的记录">一些功能和不懂的点的记录</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/computer/" title="分类于 计算机科学">计算机科学</a> <i class="ic i-angle-right"></i> <a href="/categories/computer/front/" title="分类于 前端">前端</a> <i class="ic i-angle-right"></i> <a href="/categories/computer/front/prattle/" title="分类于 杂谈">杂谈</a></div><span><a href="/2024/03/01/computer/front/prattle/%E5%89%8D%E7%AB%AF%E9%9D%A2%E8%AF%95%E9%A2%98/" title="面试题">面试题</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/computer/" title="分类于 计算机科学">计算机科学</a> <i class="ic i-angle-right"></i> <a href="/categories/computer/front/" title="分类于 前端">前端</a> <i class="ic i-angle-right"></i> <a href="/categories/computer/front/JavaScript/" title="分类于 JavaScript">JavaScript</a></div><span><a href="/2024/03/01/computer/front/JavaScript/1%E3%80%81JavaScript%E5%9F%BA%E7%A1%80%E7%AC%AC%E4%B8%80%E5%A4%A9/" title="JavaScript01">JavaScript01</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/computer/" title="分类于 计算机科学">计算机科学</a> <i class="ic i-angle-right"></i> <a href="/categories/computer/front/" title="分类于 前端">前端</a> <i class="ic i-angle-right"></i> <a href="/categories/computer/front/prattle/" title="分类于 杂谈">杂谈</a></div><span><a href="/2024/03/01/computer/front/prattle/%E4%BA%8C%E3%80%81spring%E4%BA%8B%E5%8A%A1/" title="spring事务">spring事务</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/computer/" title="分类于 计算机科学">计算机科学</a> <i class="ic i-angle-right"></i> <a href="/categories/computer/StochasticAlgorithm/" title="分类于 随机算法">随机算法</a></div><span><a href="/2025/03/16/computer/ComputationalGeometry/lec1%20%E8%89%BA%E6%9C%AF%E7%94%BB%E5%BB%8A%E9%97%AE%E9%A2%98(%E4%B8%AA%E4%BA%BA%E6%80%BB%E7%BB%93%E7%89%88/" title="lec1 介绍(个人总结版)">lec1 介绍(个人总结版)</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/computer/" title="分类于 计算机科学">计算机科学</a> <i class="ic i-angle-right"></i> <a href="/categories/computer/front/" title="分类于 前端">前端</a> <i class="ic i-angle-right"></i> <a href="/categories/computer/front/prattle/" title="分类于 杂谈">杂谈</a></div><span><a href="/2024/03/01/computer/front/prattle/%E5%8A%A8%E7%94%BB%E4%B8%8Ecanvas%E5%9B%BE%E5%BD%A2/" title="动画与canvas">动画与canvas</a></span></li><li class="item"><div class="breadcrumb"></div><span><a href="/2025/12/06/game-engine/unity/%E9%9D%A2%E7%BB%8F/%E5%90%88%E8%82%A5%E5%B8%B8%E6%98%A5%E8%97%A4/" title="未命名">未命名</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/computer/" title="分类于 计算机科学">计算机科学</a> <i class="ic i-angle-right"></i> <a href="/categories/computer/ComputationalGeometry/" title="分类于 计算几何">计算几何</a></div><span><a href="/2025/05/27/computer/ComputationalGeometry/%E4%B8%80%E4%BA%9B%E5%9F%BA%E7%A1%80%E7%9A%84%E7%9F%A5%E8%AF%86/" title="一些基础的知识">一些基础的知识</a></span></li></ul></div><div><h2>最新评论</h2><ul class="leancloud-recent-comment"></ul></div></div><div class="status"><div class="copyright">&copy; 2010 – <span itemprop="copyrightYear">2025</span> <span class="with-love"><i class="ic i-sakura rotate"></i> </span><span class="author" itemprop="copyrightHolder">IRON @ IRON</span></div><div class="powered-by">基于 <span class="exturl" data-url="aHR0cHM6Ly9oZXhvLmlv">Hexo</span> & Theme.<span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL2FtZWhpbWUvaGV4by10aGVtZS1zaG9rYQ==">Shoka</span></div></div></div></footer></div><script data-config type="text/javascript">var LOCAL={path:"2025/06/02/computer/DataAnalyze/lec8 Principles ofData Science - 副本 (3)/",favicon:{show:"（●´3｀●）やれやれだぜ",hide:"(´Д｀)大変だ！"},search:{placeholder:"文章搜索",empty:"关于 「 ${query} 」，什么也没搜到",stats:"${time} ms 内找到 ${hits} 条结果"},valine:!0,fancybox:!0,copyright:'复制成功，转载请遵守 <i class="ic i-creative-commons"></i>BY-NC-SA 协议。',ignores:[function(e){return e.includes("#")},function(e){return new RegExp(LOCAL.path+"$").test(e)}]}</script><script src="https://cdn.polyfill.io/v2/polyfill.js"></script><script src="//cdn.jsdelivr.net/combine/npm/pace-js@1.0.2/pace.min.js,npm/pjax@0.2.8/pjax.min.js,npm/whatwg-fetch@3.4.0/dist/fetch.umd.min.js,npm/animejs@3.2.0/lib/anime.min.js,npm/algoliasearch@4/dist/algoliasearch-lite.umd.js,npm/instantsearch.js@4/dist/instantsearch.production.min.js,npm/lozad@1/dist/lozad.min.js,npm/quicklink@2/dist/quicklink.umd.js"></script><script src="/js/app.js?v=0.2.5"></script></body></html><!-- rebuild by hrmmi -->